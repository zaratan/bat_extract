# Instructions pour GitHub Copilot - BatExtract

## Description du projet

BatExtract est un extracteur automatisé de données de distribution d'espèces de chauves-souris depuis les cartes officielles du Plan National d'Actions Chiroptères français. Le projet utilise l'analyse de couleurs plutôt que l'OCR pour extraire les données de distribution par département.

## Architecture actuelle (mise à jour 2025)

### Workflow automatisé complet

Le projet s'articule autour d'un workflow entièrement automatisé :

```bash
pnpm workflow  # Commande principale - exécute tout automatiquement
```

**Étapes du workflow :**

1. 🧬 **Génération des données d'espèces** → Scraping dynamique du site officiel
2. 🔍 **Découverte des URLs** → Extraction des vraies URLs d'images
3. 📥 **Téléchargement** → Récupération des cartes de distribution
4. 🎨 **Extraction** → Analyse des couleurs par département
5. 📊 **Rapport Excel** → Matrice finale espèces × départements

### Scripts individuels

| Script                  | Fichier                      | Description                                    |
| ----------------------- | ---------------------------- | ---------------------------------------------- |
| `pnpm generate-species` | `src/generateSpeciesData.ts` | Scrape la liste des espèces depuis le site web |
| `pnpm discover-urls`    | `src/discoverImageUrls.ts`   | Découvre les URLs réelles des images           |
| `pnpm download`         | `src/downloadMaps.ts`        | Télécharge les cartes de distribution          |
| `pnpm extract`          | `src/extractSpeciesData.ts`  | Extrait les données par analyse de couleurs    |
| `pnpm excel`            | `src/generateExcelReport.ts` | Génère le rapport Excel final                  |
| `pnpm workflow`         | `src/runCompleteWorkflow.ts` | Orchestrateur du workflow complet              |

### Structure des dossiers

```
src/                              # Code source
├── extractSpeciesData.ts         # Point d'entrée extraction (remplace index.ts)
├── generateSpeciesData.ts        # Génération dynamique des espèces
├── discoverImageUrls.ts          # Découverte des URLs
├── downloadMaps.ts               # Téléchargement des cartes
├── generateExcelReport.ts        # Génération rapport Excel
├── runCompleteWorkflow.ts        # Orchestrateur complet
├── multiSpeciesExtractor.ts      # Logique d'extraction multi-espèces
├── smartExtractor.ts             # Analyse de couleurs par département
└── types.ts                      # Définitions TypeScript

data/                             # Configuration statique uniquement
└── color-legend-mapping.ts       # Mapping couleurs → statuts

output/                           # Tous les fichiers générés (gitignored)
├── generated-species-data.json   # Liste d'espèces scrapée
├── discovered-image-urls.json    # URLs découvertes
├── *-distribution.json           # Données par espèce
├── consolidated-species-report.json # Rapport consolidé
└── bat-distribution-matrix.xlsx  # Matrice Excel finale

images/                           # Cartes téléchargées (gitignored)
```

## Principes d'architecture

### 1. Données dynamiques vs statiques

- ✅ **Dynamique** : Liste des espèces scrapée depuis le site officiel
- ✅ **Statique** : Configuration des couleurs (mapping RGB → statuts)
- ✅ **Séparation claire** : `data/` pour la config, `output/` pour le généré

### 2. Consistance des noms de scripts

- ✅ **Pattern uniforme** : `{action}SpeciesData.ts` ou `{action}{Object}.ts`
- ✅ **Cohérence** : Tous les scripts suivent la même convention de nommage
- ✅ **Clarté** : Le nom du fichier reflète exactement sa fonction

### 3. Gestion des outputs

- ✅ **Centralisé** : Tous les fichiers générés dans `output/`
- ✅ **Git-friendly** : Dossier `output/` entièrement dans `.gitignore`
- ✅ **Reproductible** : Génération complète possible depuis les sources

## Contexte technique

### Technologies utilisées

- **TypeScript** : Langage principal
- **Node.js + pnpm** : Runtime et gestionnaire de paquets
- **Sharp** : Traitement d'images et analyse de couleurs
- **ExcelJS** : Génération de rapports Excel avec formatage
- **node-fetch** : Scraping web pour URLs et données d'espèces

### Approche d'extraction

- **Analyse de couleurs** (pas d'OCR) : Plus robuste et précis
- **Coordonnées pré-mappées** : Chaque département a des coordonnées relatives fixes
- **Échantillonnage intelligent** : Analyse dans un rayon de 30px par département
- **Tolérance RGB** : Gestion des variations de compression d'images

### Source des données

- **Site officiel** : https://plan-actions-chiropteres.fr
- **Scraping respectueux** : Délais entre requêtes, gestion d'erreurs
- **Fallbacks** : URLs de secours si découverte échoue

## Instructions spécifiques pour Copilot

### Quand modifier le code

1. **Ajout d'espèces** : Ne pas modifier de fichiers statiques, le scraping s'en charge
2. **Nouveaux statuts de couleur** : Modifier `data/color-legend-mapping.ts`
3. **Nouveaux scripts** : Suivre le pattern `{action}SpeciesData.ts` et ajouter dans `package.json`
4. **Modifications d'output** : Toujours écrire dans `output/`, jamais dans `data/`

### Conventions de code

1. **Noms de fichiers** : camelCase avec suffixe descriptif (`generateSpeciesData.ts`)
2. **Scripts npm** : kebab-case (`generate-species`, `discover-urls`)
3. **Messages de log** : Émojis pour catégoriser (🧬 génération, 🔍 découverte, 📥 téléchargement, 🎨 extraction, 📊 rapport)
4. **Chemins de fichiers** : Toujours absolus avec `path.join(process.cwd(), ...)`

### Points d'attention

1. **Migration des données** : Les fichiers générés sont maintenant dans `output/`, pas `data/`
2. **Scripts cohérents** : `src/extractSpeciesData.ts` remplace `src/index.ts`
3. **Workflow first** : Recommander `pnpm workflow` plutôt que les scripts individuels
4. **Gestion d'erreurs** : Le workflow continue même si une étape échoue partiellement

### Tests et validation

1. **Workflow complet** : Toujours tester `pnpm workflow` après modifications importantes
2. **Scripts individuels** : Tester chaque script séparément pour debugging
3. **Linting** : Utiliser `pnpm lint:fix` pour maintenir la qualité du code
4. **Validation outputs** : Vérifier que les fichiers JSON et Excel sont bien générés

## Exemple de développement

Pour ajouter une nouvelle fonctionnalité :

1. **Créer le script** : `src/newFeatureData.ts`
2. **Ajouter dans package.json** : `"new-feature": "ts-node src/newFeatureData.ts"`
3. **Intégrer au workflow** : Ajouter l'étape dans `src/runCompleteWorkflow.ts`
4. **Tester** : `pnpm new-feature` puis `pnpm workflow`
5. **Documenter** : Mettre à jour le README.md

Cette architecture garantit un projet maintenable, reproductible et extensible.
